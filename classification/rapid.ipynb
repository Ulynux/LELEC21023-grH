{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.9.18)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/ulysse/Documents/LELEC21023-grH/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "### TO RUN\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\"Machine learning tools\"\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from classification.datasets import Dataset\n",
    "from classification.utils.audio_student import AudioUtil, Feature_vector_DS\n",
    "from classification.utils.plots import (\n",
    "    plot_decision_boundaries,\n",
    "    plot_specgram,\n",
    "    show_confusion_matrix,\n",
    ")\n",
    "from classification.utils.utils import accuracy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful functions to select, read and play the dataset sounds are provided in ``classification/utils/audio_student.py``. <br>\n",
    "\n",
    "As for the H1, you will have to fill some short pieces of code, as well as answer some questions. We already created cells for you to answer the questions to ensure you don't forget it ;). <br>\n",
    "You will find the zones to be briefly filled  with a ``### TO COMPLETE`` in the cells below.\n",
    "\n",
    "<font size=6 color=#009999> 2. Training and Evaluating models on audio signals [~1h30-2h] </font> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "dataset = Dataset()\n",
    "classnames = dataset.list_classes()\n",
    "\n",
    "print(\"\\n\".join(classnames))\n",
    "print(len(classnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "fm_dir = \"../../feature_mat/\"  # where to save the features matrices\n",
    "model_dir = \"data/models/\"  # where to save the models\n",
    "os.makedirs(fm_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In H1, it was not made explicit what we choose as input for the classification model, a.k.a. ``feature vector`` (it was shown in the illustration). <br>\n",
    "The objective is, on the transmitter side, to compute a feature vector containing enough information about the audio signal we want to classify, but not too much in order to limit the data which has to be transmitted wirelessly. This is why in H1 we implemented the ``Hz2Mel`` conversion: a very simple compression of the frequency content. <br>\n",
    "The feature vector we will use here simply consists in taking the first 20 columns of the melspectrogram, corresponding to ~1s, then reshaping it as a vector. This means each feature vector contains ``400`` coefficients, with 20 columns of 20 mels each.  <br>\n",
    "\n",
    "Once the feature vector has been recovered on the receiver side, we can apply any computation on it to guess the right class this sound belongs to. Today, we will simply reuse the simple KNN and LDA classifiers and look at what we already get. \n",
    "\n",
    "<font size=3 color=#FF0000> Important :</font> <br>\n",
    "The analyses that follow are given as food for thoughts. They are not given as step by step improvements of the classifier.\n",
    "\n",
    "<font size=5 color=#009999> 2.1. Creation of the dataset </font> <br>\n",
    "\n",
    "``Feature_vector_DS`` is a class defined in ``classification/utils/audio_student.py``. <br>\n",
    "The functions ``__len__`` and ``__getitem__`` are implemented, meaning you can call :\n",
    "- ``len(myds)`` to get the number of sounds in it.\n",
    "- ``myds[classname,j]`` to get the melspectrogram of the ``j``-th sound from class ``classname``. <br>\n",
    "\n",
    "Two other useful functions are provided:\n",
    "- ``get_audiosignal`` returning the temporal audiosignal at the specified index.\n",
    "- ``display`` playing the sound and showing the associated mel-spectrogram at the specified index.\n",
    "\n",
    "<font size=3 color=#FF0000> Important :</font> <br>\n",
    "Before being able to run the cells below, you will have to reuse your functions from H1 to fill the missing lines in ``audio_student.py`` at ``###TO COMPLETE`` locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "\n",
    "\"Creation of the dataset\"\n",
    "myds = Feature_vector_DS(dataset, Nft=512, nmel=20, duration=950 )\n",
    "\n",
    "\"Some attributes...\"\n",
    "myds.nmel\n",
    "myds.duration\n",
    "myds.shift_pct\n",
    "myds.sr\n",
    "myds.data_aug\n",
    "myds.ncol\n",
    "\n",
    "# idx = 10\n",
    "# myds.display([\"chainsaw\", idx])\n",
    "\n",
    "\n",
    "# idx = 1\n",
    "# myds.display([\"fireworks\", idx])\n",
    "# print(myds[\"fire\", 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the cell above many times, you should notice it is always the beginning of the sound that is taken for creating the feature vector. ``shift_pct`` meaning *shift percentage* allows to roll the audio signal with a random factor upper bounded by this value. Change ``shift_pct`` to ``0.2`` and observe what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "\"Random split of 70:30 between training and validation\"\n",
    "train_pct = 0.7\n",
    "featveclen = len(myds[\"fire\", 0])  # number of items in a feature vector\n",
    "# print(f\"Feature vector length: {featveclen}\")\n",
    "nitems = len(myds)  # number of sounds in the dataset\n",
    "naudio = dataset.naudio  # number of audio files in each class\n",
    "nclass = dataset.nclass  # number of classes\n",
    "data_aug_factor = 1\n",
    "naudio_sum = sum(naudio.values())\n",
    "class_ids_aug = np.concatenate(\n",
    "    [np.repeat(classname, naudio[classname] * data_aug_factor) for classname in classnames]\n",
    ")\n",
    "\n",
    "X = np.zeros((data_aug_factor * naudio_sum, featveclen))\n",
    "for s in range(data_aug_factor):\n",
    "    for class_idx, classname in enumerate(classnames):\n",
    "        for idx in range(naudio[classname]):\n",
    "            featvec = myds[classname, idx]\n",
    "            X[s * nclass * naudio[classname] + class_idx * naudio[classname] + idx, :] = featvec\n",
    "np.save(fm_dir + \"feature_matrix_2D.npy\", X)\n",
    "# Assuming classnames is already defined\n",
    "\n",
    "# Print the names of the classes\n",
    "print(\"Class names:\", classnames)\n",
    "\n",
    "\n",
    "X = np.load(fm_dir+\"feature_matrix_2D.npy\")\n",
    "\n",
    "\"Labels\"\n",
    "y = class_ids_aug.copy()\n",
    "classnames = np.unique(y)\n",
    "\n",
    "print(f\"Shape of the feature matrix : {X.shape}\")\n",
    "print(f\"Number of labels : {len(y)}\")\n",
    "unique_classes, class_counts = np.unique(y, return_counts=True)\n",
    "\n",
    "# Print the counts for each class\n",
    "for classname, count in zip(unique_classes, class_counts):\n",
    "    print(f\"Class '{classname}': {count} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might notice that ``feature_matrix_2D.npy`` has been saved in ``data/feature_matrices/`` and can now be loaded instead of recomputing it at every run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=#009999> 2.2. First audio classification, metrics and dataset splitting </font> <br>\n",
    "\n",
    "For now we have only prepared the dataset, it remains to feed it to the classifiers. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 14  # Number of principal components kept\n",
    "model_pca = PCA(n_components=n, whiten=True)\n",
    "# [4] Model training and selection.\n",
    "K = 8\n",
    "model_knn = KNeighborsClassifier(n_neighbors=K, weights=\"distance\")\n",
    "\n",
    "model_rf = RandomForestClassifier(n_estimators=100, \n",
    "                             max_depth=2,\n",
    "                             min_impurity_decrease=0.01\n",
    "                             ,min_samples_leaf=2,\n",
    "                             min_samples_split=3,\n",
    "                             random_state=0)\n",
    "model_lda = LDA(\n",
    "    solver=\"svd\",\n",
    "    shrinkage=None,\n",
    "    priors=None,\n",
    "    n_components=None,\n",
    "    store_covariance=False,\n",
    "    tol=0.0001,\n",
    "    covariance_estimator=None,\n",
    ") \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the toy example, we keep the ``accuracy`` and ``confusion matrix`` as performance metrics. <br>\n",
    "\n",
    "Note that here we are not especially interested in a model selection hence we only split the dataset in training and testing parts but we don't split the training set in learning/validation parts. The models are trained on the entire training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=#009999> 2.6. Augmenting the data </font> <br>\n",
    "\n",
    "In order to make our classifier more robust to some common transformations of the audio signal such as ``time shift``, ``AWGN``, or a ``transfer function``, an idea consists in feeding the classifier with such transformations. A popular approach is to create new feature vectors based on transformed versions of the sounds from the original dataset, this is called ``data augmentation``. Data augmentation is also often used when there is few data to train a model. <br>\n",
    "\n",
    "The functions to augment your data are written in ``utils/audio_student.py``, we already implemented ``time_shift``, ``echo`` and ``spectro_aug_timefreq_masking`` for you. Try to implement ``scaling``, ``add_noise``, ``filter``, ``add_bg`` and even more data augmentation techniques if you want, and check their working in the cell below. <br>\n",
    "\n",
    "<u>Tip</u>: to avoid restarting the notebook kernel for each modification, you can temporarily insert the ``AudioUtil`` class in a new cell and make your tests until it is working as expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "myds.data_aug = None  # Ensure\n",
    "\n",
    "cls_index = [\"fire\", 2]\n",
    "\n",
    "sound = dataset.__getitem__(cls_index)\n",
    "name = dataset.__getname__(cls_index)\n",
    "audio = AudioUtil.open(sound)\n",
    "audio_tmp = AudioUtil.open(sound)\n",
    "AudioUtil.play(audio)\n",
    "audio2 = AudioUtil.resample(audio, 11025)\n",
    "audio2 = AudioUtil.pad_trunc(audio2, 5000)\n",
    "\n",
    "audio3 = AudioUtil.time_shift(audio2, 0.5)\n",
    "audio4 = AudioUtil.scaling(audio2)\n",
    "audio5 = AudioUtil.add_noise(audio_tmp, sigma=1e-4)  # Create a copy before adding noise\n",
    "audio6 = AudioUtil.echo(audio2)\n",
    "# audio7 = AudioUtil.add_bg(audio2, dataset)\n",
    "\n",
    "melspec = AudioUtil.melspectrogram(audio2, fs2=11025)\n",
    "melspec2 = AudioUtil.spectro_aug_timefreq_masking(melspec, max_mask_pct=0.1)\n",
    "\n",
    "\"Plot\"\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "ax1 = fig.add_axes([0.05, 0.05, 0.28, 0.9])\n",
    "ax2 = fig.add_axes([0.38, 0.05, 0.28, 0.9])\n",
    "ax3 = fig.add_axes([0.7, 0.05, 0.28, 0.9])\n",
    "\n",
    "ax1.plot(audio2[0], label=\"Original\")\n",
    "ax1.plot(audio3[0] + 1, label=\"Time shifted\")\n",
    "ax1.plot(audio4[0] + 2, label=\"Rescaled\")\n",
    "ax1.plot(audio5[0] + 3, label=\"Noisy\")\n",
    "ax1.plot(audio6[0] + 4, label=\"With echos\")\n",
    "# ax1.plot(audio7[0] + 5, label=\"With background sound\")\n",
    "ax1.legend()\n",
    "\n",
    "plot_specgram(melspec, ax2, is_mel=True, title=name, tf=len(audio2[0]) / audio2[1])\n",
    "ax2.set_title(\"Melspectrogram\")\n",
    "plot_specgram(melspec2, ax3, is_mel=True, title=name, tf=len(audio2[0]) / audio2[1])\n",
    "ax3.set_title(\"Corrupted melspectrogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a new augmented dataset and observe if the classification results improve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "### TO RUN\n",
    "# Initialize the feature matrix and labels for multiple shift_pct values\n",
    "shift_pct_values = np.arange(0, 0.96, 0.02).tolist()  # List of shift_pct values\n",
    "X_aug_list = []\n",
    "y_aug_list = []\n",
    "\n",
    "# naudio_sum = sum(naudio.values())\n",
    "# for shift_pct in tqdm(shift_pct_values, desc=\"Processing shift_pct values\"):\n",
    "#     # Create a Feature_vector_DS for the current shift_pct\n",
    "#     myds_shifted = Feature_vector_DS(dataset, Nft=512, nmel=20, duration=950, shift_pct=shift_pct)\n",
    "#     myds_shifted.mod_data_aug([\"time_shift\", \"noise\", \"echo\",\"background_noise\"])\n",
    "    \n",
    "#     # Initialize feature matrix and labels for the current shift_pct\n",
    "#     X_aug_shifted = np.zeros((myds_shifted.data_aug_factor * naudio_sum, featveclen))\n",
    "#     y_aug_shifted = np.empty((myds_shifted.data_aug_factor * naudio_sum), dtype=object)\n",
    "    \n",
    "#     # Generate feature vectors and labels\n",
    "#     for s in range(myds_shifted.data_aug_factor):\n",
    "#         offset = 0\n",
    "#         for class_idx, classname in enumerate(classnames):\n",
    "#             num_samples = naudio[classname]  # Number of samples for the current class\n",
    "#             for idx in range(num_samples):\n",
    "#                 featvec = myds_shifted[classname, idx]\n",
    "#                 X_aug_shifted[s * naudio_sum + offset + idx, :] = featvec\n",
    "#                 y_aug_shifted[s * naudio_sum + offset + idx] = classname\n",
    "#             offset += num_samples  # Update the offset for the next class\n",
    "    \n",
    "#     # Append the current shift_pct data to the lists\n",
    "#     print(f\"Shape of the feature matrix for shift_pct={shift_pct} : {X_aug_shifted.shape}\")\n",
    "#     X_aug_list.append(X_aug_shifted)\n",
    "#     y_aug_list.append(y_aug_shifted)\n",
    "\n",
    "# # Concatenate all feature matrices and labels\n",
    "# X_aug = np.vstack(X_aug_list)\n",
    "# y_aug = np.concatenate(y_aug_list)\n",
    "\n",
    "# # Save the feature matrices\n",
    "# np.save(fm_dir + \"feature_matrix_2D_test_background_noise.npy\", X_aug)\n",
    "# np.save(fm_dir + \"labels_2D_test_background_noise.npy\", y_aug)\n",
    "\n",
    "# Load the feature matrices (if necessary)\n",
    "X_aug = np.load(fm_dir + \"feature_matrix_2D_test_background_noise.npy\")\n",
    "y_aug = np.load(fm_dir + \"labels_2D_test_background_noise.npy\", allow_pickle=True)\n",
    "\n",
    "print(f\"Shape of the feature matrix : {X_aug.shape}\")\n",
    "print(f\"Number of labels : {len(y_aug)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=#009999> 2.7. Getting it all together </font> <br>\n",
    "\n",
    "Now that some aspects to be considered during the model training and analysis have been presented, it remains to train and save a final model that will be used for further predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "X_aug -= np.mean(X_aug, axis=0)\n",
    "X_aug /= np.linalg.norm(X_aug, axis=0)\n",
    "X_train_normalized, X_test_normalized, y_train, y_test = train_test_split(X_aug, y_aug, test_size=0.3, random_state=42)\n",
    "# [2] (optional) Data normalization\n",
    "# [3] Initialize the Random Forest model\n",
    "best_rf = RandomForestClassifier(\n",
    "    max_depth=10,\n",
    "    min_impurity_decrease=0.001,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# [4] Evaluate RF without PCA\n",
    "n_splits = 5  # Number of cross-validation splits\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies_no_pca = []\n",
    "for train_idx, val_idx in kf.split(X_train_normalized, y_train):\n",
    "    # Train and evaluate the Random Forest model without PCA\n",
    "    best_rf.fit(X_train_normalized[train_idx], y_train[train_idx])\n",
    "    y_pred = best_rf.predict(X_train_normalized[val_idx])\n",
    "    accuracy = accuracy_score(y_train[val_idx], y_pred)\n",
    "    accuracies_no_pca.append(accuracy)\n",
    "\n",
    "mean_accuracy_no_pca = np.mean(accuracies_no_pca)\n",
    "print(f\"Mean Accuracy without PCA: {mean_accuracy_no_pca * 100:.2f}%\")\n",
    "\n",
    "# [5] Evaluate RF with PCA\n",
    "pca_components = range(1, min(X_train_normalized.shape[1], 50))  # Test 1 to 20 components\n",
    "mean_accuracies_with_pca = []\n",
    "\n",
    "for n_components in pca_components:\n",
    "    accuracies_with_pca = []\n",
    "    pca = PCA(n_components=n_components, whiten=True)\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(X_train_normalized, y_train):\n",
    "        # Apply PCA\n",
    "        \n",
    "        X_train_pca = pca.fit_transform(X_train_normalized[train_idx])\n",
    "        X_val_pca = pca.transform(X_train_normalized[val_idx])\n",
    "        \n",
    "        # Train and evaluate the Random Forest model\n",
    "        best_rf.fit(X_train_pca, y_train[train_idx])\n",
    "        y_pred = best_rf.predict(X_val_pca)\n",
    "        accuracy = accuracy_score(y_train[val_idx], y_pred)\n",
    "        accuracies_with_pca.append(accuracy)\n",
    "    \n",
    "    # Compute the mean accuracy for the current number of PCA components\n",
    "    mean_accuracy_with_pca = np.mean(accuracies_with_pca)\n",
    "    mean_accuracies_with_pca.append(mean_accuracy_with_pca)\n",
    "    print(f\"PCA components: {n_components}, Mean Accuracy: {mean_accuracy_with_pca * 100:.2f}%\")\n",
    "\n",
    "# [6] Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(pca_components, [acc * 100 for acc in mean_accuracies_with_pca], marker='o', label='With PCA')\n",
    "plt.axhline(y=mean_accuracy_no_pca * 100, color='r', linestyle='--', label='Without PCA')\n",
    "plt.xlabel('Number of PCA Components')\n",
    "plt.xticks(np.arange(0, 50, 5))\n",
    "plt.ylabel('Mean Accuracy (%)')\n",
    "plt.title('Comparison of Random Forest with and without PCA')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "pdf_filename = \"rf_with_vs_without_pca.pdf\"\n",
    "with PdfPages(pdf_filename) as pdf:\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "print(f\"Plot saved as {pdf_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "pdf_filename = \"rf_with_vs_without_pca.pdf\"\n",
    "with PdfPages(pdf_filename) as pdf:\n",
    "    pdf.savefig()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# [1] Create dataset of feature vectors and split it.\n",
    "print(f\"Number of labels: {y_aug.shape}\")\n",
    "\n",
    "\n",
    "# X_aug = np.load(fm_dir + \"feature_matrix_2D_aug.npy\")\n",
    "# y_aug = np.load(fm_dir + \"labels_2D_aug.npy\", allow_pickle=True)\n",
    "\n",
    "# X_aug = X_aug / np.linalg.norm(X_aug, axis=1, keepdims=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_aug, y_aug, test_size=0.3, stratify=y_aug\n",
    ")  # random_state=1\n",
    "pca = PCA(n_components=25, whiten=True)\n",
    "\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "# X_train -= np.mean(X_train, axis=0)\n",
    "# X_test -= np.mean(X_test, axis=0)\n",
    "# [2] (optional) Data normalization\n",
    "\n",
    "\n",
    "filename_pca = \"pca_25_components.pickle\"\n",
    "pickle.dump(pca, open(model_dir + filename_pca, \"wb\"))\n",
    "# Apply PCA with 10 components\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# [3] Model training and selection using Random Forest\n",
    "best_rf = RandomForestClassifier(\n",
    "    max_depth=10,\n",
    "    min_impurity_decrease=0.001,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "n_splits = 5\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "accuracies_rf = np.zeros((n_splits,))\n",
    "\n",
    "for k, idx in enumerate(kf.split(X_train, y_train)):\n",
    "    idx_learn, idx_val = idx\n",
    "    best_rf.fit(X_train[idx_learn], y_train[idx_learn])\n",
    "    prediction_rf = best_rf.predict(X_train[idx_val])\n",
    "    accuracies_rf[k] = accuracy_score(y_train[idx_val], prediction_rf)\n",
    "\n",
    "# [4] Save the trained model\n",
    "filename_model = \"best_rf_model.pickle\"\n",
    "pickle.dump(best_rf, open(model_dir + filename_model, \"wb\"))\n",
    "\n",
    "# [5] Evaluate the model\n",
    "print(f\"Mean accuracy with Random Forest 5-Fold CV: {100 * accuracies_rf.mean():.1f}%\")\n",
    "print(f\"Std deviation in accuracy with 5-Fold CV: {100 * accuracies_rf.std():.1f}%\")\n",
    "\n",
    "y_pred = best_rf.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test set accuracy with Random Forest: {accuracy_rf * 100:.2f}%\")\n",
    "\n",
    "# Show the confusion matrix\n",
    "show_confusion_matrix(y_pred, y_test, classnames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LELEC2103-grH",
   "language": "python",
   "name": "lelec2103-grh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
